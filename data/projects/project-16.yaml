modalID: 16
title: "Edinburgh 2018"
date: "20 April 2018"
img: 16.jpg
imgcredit: "Photograph taken by [Giuseppe Milo](https://www.flickr.com/photos/giuseppemilo/16947297009)"
category: "Future Meeting"
description:
  - firstname: Carlos
    lastname: Zednik
    title: "From Machine Learning to Machine Intelligence"
    abstract: "Recent progress in artificial intelligence sparks new interest in an old philosophical question: Can machines think? In this talk I will consider the use of Machine Learning (ML) methods to develop intelligent thinking machines. Two criteria will be considered: behavioral indistinguishability and procedural (or algorithmic) similarity. It seems probable that ML methods will eventually yield computers that satisfy the former. But what about the latter? The inner workings of ML-programmed computers such as deep neural networks and reinforcement learning agents may be no easier to understand than those of human cognizers. Thus, I will review empirical methods for addressing this 'Black Box Problem', e.g. experimental techniques and methods of mathematical analysis. I will also consider a priori reasons for thinking that ML-programmed computers will not only become behaviorally indistinguishable from humans, but that they will also exhibit a degree of procedural similarity. Because these computers are nurtured and situated in the real-world environment that is also inhabited by humans, the methods they will acquire in order to engage that environment are likely to mirror our own."
  - firstname: Marta
    lastname: Halina
    title: "Insightful AI"
    abstract: |
      In March 2016, Google DeepMind’s computer programme AlphaGo surprised the world by defeating the world-champion Go player, Lee Sedol. Go is a strategic game with a vast search space (including many more legal positions than atoms in the observable universe), which humans have been playing and studying for over 3000 years. Watching the tournament, the Go community was struck by AlphaGo’s moves—they were surprising, original, “beautiful”, and extremely effective. The moves were described as “creative” by the Go community and in follow-up talks on the subject, Demis Hassabis—leading AI developer and CEO of Google DeepMind—defended them as such. Should we understand AlphaGo as exhibiting human-like insight? Answering this question requires having an account of what constitutes insightful thought in humans and developing tests for measuring this ability in nonhuman systems. 

      In this talk, I draw on research in cognitive psychology to evaluate contemporary progress in AI, specifically whether new programs such as AlphaGo are best understood as exhibiting insight. Recent cognitive accounts of insight emphasise the importance of mental models (e.g., general causal models of the physical world) for generating insightful behaviour. Such models allow individuals to solve problems and make predictions in situations they have never encountered before. How do we determine whether and when new artificial agents are capable of employing such models? Here insights from comparative psychology can help. Over the last 40 years, comparative psychologists have been developing tests for identifying the use of mental models in nonhuman organisms. The application of such tests to AI may help us not only interpret Deep Neural Networks, but suggest ways in which the technology might be improved.

  - firstname: "Vincent"
    lastname: "Müller"
    title: "Neurosurveillance"
    abstract: "The traditional problem of surveillance or privacy concerns personal data and behaviour – and it is believed that what we humans think, feel, desire and plan must be private because access to these cognitive processes is practically impossible, or even impossible in principle. We argue that current technical developments in live brain-imaging, EEG, brain implants and other brain-computer interfaces (BCIs) make it practically possible to detect data from the brain, analyse that data and extract significant cognitive content – including content that is not accessible to the subject themselves. Though all current techniques require close proximity, they do not require a conscious or collaborative subject. We conclude that neurosurveillance is a real, current, threat to privacy. - These considerations have relevance for two traditional issues: a) the alleged epistemic inaccessibility of phenomenal content in ‘other minds’ and b) the relevance of the philosophy of mind for empirical questions, generally."
    



